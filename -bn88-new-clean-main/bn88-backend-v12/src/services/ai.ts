// src/services/ai.ts

// =======================
// Types
// =======================

export type AskPloyOptions = {
  openaiKey: string;
  userText: string;
  systemPrompt?: string;
  model?: string;
  temperature?: number;
  top_p?: number;
  max_tokens?: number;
};

export type AskAIOptions = {
  apiKey: string;
  userText: string;
  systemPrompt?: string;
  model?: string;
  temperature?: number;
  topP?: number;
  maxTokens?: number;
  knowledgeSnippets?: string[]; // ‡πÉ‡∏ä‡πâ‡πÅ‡∏ô‡∏ö context ‡πÄ‡∏û‡∏¥‡πà‡∏°
};

// =======================
// Core helpers
// =======================

function buildMessages(
  systemPrompt: string | undefined,
  userText: string,
  knowledgeSnippets?: string[]
) {
  const baseSystem =
    systemPrompt?.trim() ||
    "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ä‡∏∑‡πà‡∏≠ '‡∏û‡∏µ‡πà‡∏û‡∏•‡∏≠‡∏¢' ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å ‡πÅ‡∏•‡∏∞‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢";

  const withKnowledge =
    knowledgeSnippets && knowledgeSnippets.length > 0
      ? `${baseSystem}\n\n# ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á\n${knowledgeSnippets
          .map((c, i) => `(${i + 1}) ${c}`)
          .join("\n\n")}`
      : baseSystem;

  return [
    { role: "system", content: withKnowledge },
    { role: "user", content: userText },
  ];
}

// =======================
// askPloy (‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö LINE webhook)
// =======================

export async function askPloy({
  model,
  systemPrompt,
  userText,
  openaiKey,
  temperature = 0.3,
  top_p = 0.9,
  max_tokens = 600,
}: AskPloyOptions): Promise<string> {
  if (!openaiKey) {
    return "‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ OpenAI API Key ‡∏Ñ‡πà‡∏∞ ‡πÅ‡∏≠‡∏î‡∏°‡∏¥‡∏ô‡∏•‡∏≠‡∏á‡πÄ‡∏ä‡πá‡∏Ñ‡∏´‡∏ô‡πâ‡∏≤ Bots ‚Üí Secrets ‡∏ô‡∏∞‡∏Ñ‡∏∞ üíõ";
  }

  const finalModel = model || process.env.OPENAI_MODEL || "gpt-4o-mini";

  try {
    const res = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${openaiKey}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: finalModel,
        temperature,
        top_p,
        max_tokens,
        messages: buildMessages(systemPrompt, userText),
      }),
    });

    if (!res.ok) {
      const txt = await res.text().catch(() => "");
      console.error("OpenAI error (askPloy):", res.status, txt);
      return "‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡πà‡∏∞ ‡∏£‡∏∞‡∏ö‡∏ö AI ‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß ‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏∞‡∏Ñ‡∏∞ üôè";
    }

    const data: any = await res.json();
    return (
      data?.choices?.[0]?.message?.content?.trim() ??
      "‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡πà‡∏∞ ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏à‡∏≤‡∏Å AI ‡∏Ñ‡πà‡∏∞"
    );
  } catch (err) {
    console.error("OpenAI fetch error (askPloy):", err);
    return "‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡πà‡∏∞ ‡∏£‡∏∞‡∏ö‡∏ö AI ‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß ‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏∞‡∏Ñ‡∏∞ üôè";
  }
}

// =======================
// askAI (‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ / Dashboard)
// =======================

export async function askAI({
  apiKey,
  userText,
  systemPrompt,
  model,
  temperature = 0.3,
  topP = 0.9,
  maxTokens = 600,
  knowledgeSnippets,
}: AskAIOptions): Promise<string> {
  if (!apiKey) {
    throw new Error("missing_openai_api_key");
  }

  const finalModel = model || process.env.OPENAI_MODEL || "gpt-4o-mini";

  const res = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: {
      Authorization: `Bearer ${apiKey}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      model: finalModel,
      temperature,
      top_p: topP,
      max_tokens: maxTokens,
      messages: buildMessages(systemPrompt, userText, knowledgeSnippets),
    }),
  });

  if (!res.ok) {
    const txt = await res.text().catch(() => "");
    console.error("OpenAI error (askAI):", res.status, txt);
    throw new Error("internal_error");
  }

  const data: any = await res.json();
  return (
    data?.choices?.[0]?.message?.content?.trim() ??
    "‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡πà‡∏∞ ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏à‡∏≤‡∏Å AI ‡∏Ñ‡πà‡∏∞"
  );
}

