// src/services/ai.ts

// =======================
// Types
// =======================

export type AskPloyOptions = {
  openaiKey: string;
  userText: string;
  systemPrompt?: string;
  model?: string;
  temperature?: number;
  top_p?: number;
  max_tokens?: number;
};

export type AskAIOptions = {
  apiKey: string;
  userText: string;
  systemPrompt?: string;
  model?: string;
  temperature?: number;
  topP?: number;
  maxTokens?: number;
  knowledgeSnippets?: string[]; // ‡πÉ‡∏ä‡πâ‡πÅ‡∏ô‡∏ö context ‡πÄ‡∏û‡∏¥‡πà‡∏° (RAG / KB)
};

// =======================
// Core helpers
// =======================

/**
 * ‡∏™‡∏£‡πâ‡∏≤‡∏á messages ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤ OpenAI Chat Completions
 * - systemPrompt: ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏™‡πà‡∏á‡∏°‡∏≤ ‡∏à‡∏∞‡πÉ‡∏ä‡πâ default persona "‡∏û‡∏µ‡πà‡∏û‡∏•‡∏≠‡∏¢"
 * - knowledgeSnippets: ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏à‡∏∞‡πÄ‡∏≠‡∏≤‡∏°‡∏≤‡∏ï‡πà‡∏≠‡∏ó‡πâ‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á
 */
function buildMessages(
  systemPrompt: string | undefined,
  userText: string,
  knowledgeSnippets?: string[]
) {
  const baseSystem =
    systemPrompt?.trim() ||
    "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ä‡∏∑‡πà‡∏≠ '‡∏û‡∏µ‡πà‡∏û‡∏•‡∏≠‡∏¢' ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å ‡πÅ‡∏•‡∏∞‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢";

  const withKnowledge =
    knowledgeSnippets && knowledgeSnippets.length > 0
      ? `${baseSystem}\n\n# ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á\n${knowledgeSnippets
          .map((c, i) => `(${i + 1}) ${c}`)
          .join("\n\n")}`
      : baseSystem;

  return [
    { role: "system", content: withKnowledge },
    { role: "user", content: userText },
  ];
}

// =======================
// askPloy (‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö LINE webhook)
// =======================

/**
 * ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà LINE webhook ‡πÉ‡∏ä‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏´‡πâ "‡∏û‡∏µ‡πà‡∏û‡∏•‡∏≠‡∏¢" ‡∏ï‡∏≠‡∏ö‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤
 * - ‡πÑ‡∏°‡πà‡πÇ‡∏¢‡∏ô error ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏ó‡∏µ‡πà webhook (‡∏à‡∏∞ return ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° fallback ‡πÅ‡∏ó‡∏ô)
 * - ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ API key: ‡πÅ‡∏à‡πâ‡∏á‡πÅ‡∏≠‡∏î‡∏°‡∏¥‡∏ô‡πÉ‡∏´‡πâ‡πÑ‡∏õ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤ Bots ‚Üí Secrets
 */
export async function askPloy({
  model,
  systemPrompt,
  userText,
  openaiKey,
  temperature = 0.3,
  top_p = 0.9,
  max_tokens = 600,
}: AskPloyOptions): Promise<string> {
  if (!openaiKey) {
    return "‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ OpenAI API Key ‡∏Ñ‡πà‡∏∞ ‡πÅ‡∏≠‡∏î‡∏°‡∏¥‡∏ô‡∏•‡∏≠‡∏á‡πÄ‡∏ä‡πá‡∏Ñ‡∏´‡∏ô‡πâ‡∏≤ Bots ‚Üí Secrets ‡∏ô‡∏∞‡∏Ñ‡∏∞ üíõ";
  }

  const finalModel = model || process.env.OPENAI_MODEL || "gpt-4o-mini";

  try {
    const res = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${openaiKey}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: finalModel,
        temperature,
        top_p,
        max_tokens,
        messages: buildMessages(systemPrompt, userText),
      }),
    });

    if (!res.ok) {
      const txt = await res.text().catch(() => "");
      console.error("OpenAI error (askPloy):", res.status, txt);
      return "‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡πà‡∏∞ ‡∏£‡∏∞‡∏ö‡∏ö AI ‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß ‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏∞‡∏Ñ‡∏∞ üôè";
    }

    const data: any = await res.json().catch((e) => {
      console.error("OpenAI JSON parse error (askPloy):", e);
      return null;
    });

    const content: string | undefined =
      data?.choices?.[0]?.message?.content ??
      data?.choices?.[0]?.text ??
      undefined;

    if (!content || typeof content !== "string") {
      console.warn("OpenAI empty content (askPloy):", data);
      return "‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡πà‡∏∞ ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏à‡∏≤‡∏Å AI ‡∏Ñ‡πà‡∏∞ ‡∏•‡∏≠‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏∞‡∏Ñ‡∏∞ üôè";
    }

    return content.trim();
  } catch (err) {
    console.error("OpenAI fetch error (askPloy):", err);
    return "‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡πà‡∏∞ ‡∏£‡∏∞‡∏ö‡∏ö AI ‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß ‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏∞‡∏Ñ‡∏∞ üôè";
  }
}

// =======================
// askAI (‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ / Dashboard / Tools ‡∏≠‡∏∑‡πà‡∏ô)
// =======================

/**
 * ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô AI ‡πÅ‡∏ö‡∏ö general-purpose
 * - ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô Dashboard / dev tools / ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏≠‡∏∑‡πà‡∏ô
 * - ‡∏ñ‡πâ‡∏≤ error ‡∏à‡∏∞ throw ‡πÉ‡∏´‡πâ caller handle ‡∏ï‡πà‡∏≠‡πÄ‡∏≠‡∏á
 */
export async function askAI({
  apiKey,
  userText,
  systemPrompt,
  model,
  temperature = 0.3,
  topP = 0.9,
  maxTokens = 600,
  knowledgeSnippets,
}: AskAIOptions): Promise<string> {
  if (!apiKey) {
    throw new Error("missing_openai_api_key");
  }

  const finalModel = model || process.env.OPENAI_MODEL || "gpt-4o-mini";

  try {
    const res = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${apiKey}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: finalModel,
        temperature,
        top_p: topP,
        max_tokens: maxTokens,
        messages: buildMessages(systemPrompt, userText, knowledgeSnippets),
      }),
    });

    if (!res.ok) {
      const txt = await res.text().catch(() => "");
      console.error("OpenAI error (askAI):", res.status, txt);
      throw new Error("internal_error");
    }

    const data: any = await res.json().catch((e) => {
      console.error("OpenAI JSON parse error (askAI):", e);
      throw new Error("internal_error");
    });

    const content: string | undefined =
      data?.choices?.[0]?.message?.content ??
      data?.choices?.[0]?.text ??
      undefined;

    if (!content || typeof content !== "string") {
      console.warn("OpenAI empty content (askAI):", data);
      throw new Error("empty_ai_response");
    }

    return content.trim();
  } catch (err) {
    console.error("OpenAI fetch error (askAI):", err);
    throw err;
  }
}

